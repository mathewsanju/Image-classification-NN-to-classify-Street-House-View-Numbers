{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lO11-c_0OtzO"
   },
   "source": [
    "## Sanju Mathew - Project on Neural Networks\n",
    "\n",
    "### Objective\n",
    "* The objective of the project is to learn how to implement a simple image classification pipeline based on a deep neural network.\n",
    "\n",
    "#### Task: Data fetching and understanding the train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "9VVj03aEP1vY",
    "outputId": "055ab211-7dac-4b09-dd4b-6f5044846c13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "_t6sheBwOtzP",
    "outputId": "bd7df62a-d040-4f11-ee70-b2a18e9d9d7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from keras import optimizers, regularizers\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VFL0oluVOtzT",
    "outputId": "d7312d10-7875-4f4d-b94a-8fcb89c03c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 32, 32) (42000,) (18000, 32, 32) (18000,)\n"
     ]
    }
   ],
   "source": [
    "Data = h5py.File('/content/drive/My Drive/DLCP/SVHN/data/SVHN_single_grey1.h5','r')\n",
    "X_train = Data['X_train'][:]\n",
    "y_train = Data['y_train'][:]\n",
    "X_test = Data['X_test'][:]\n",
    "y_test = Data['y_test'][:]\n",
    "Data.close()\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "xdEMw9sAOtzX",
    "outputId": "096257ea-7daa-44aa-c2b4-64bc4c5758dd",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  2\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.show()\n",
    "print('Label: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "CUC1zbWdOtzZ",
    "outputId": "fafbdb38-876a-4ffd-d6ba-7b27458d99c7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_test[0], cmap='gray')\n",
    "plt.show()\n",
    "print('Label: ', y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "SOJlQfLvOtzc",
    "outputId": "5e2d4ad4-a6af-4859-a20d-82ec11f90b27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([4186, 4172, 4197, 4281, 4188, 4232, 4168, 4192, 4188, 4196]))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "3bpfRVABOtze",
    "outputId": "7a78befa-7917-45d2-f4f7-c7aa3ca54338"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([1814, 1828, 1803, 1719, 1812, 1768, 1832, 1808, 1812, 1804]))"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3ZNIET9tOtzg",
    "outputId": "18fca35d-cb40-4f44-f3b7-ea8a7a666abd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024) (18000, 1024) (42000, 10) (18000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "y_train = to_categorical(y_train,num_classes=10)\n",
    "y_test = to_categorical(y_test,num_classes=10)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reshape input\n",
    "* Normalise\n",
    "* One hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gfvXfXzBOtzi",
    "outputId": "31d5e360-c03a-4bf4-94f2-205100eebde6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGKYUd-munFe"
   },
   "source": [
    "#### Task: Implement and apply a deep neural network classifier including feedforward neural network, RELU, activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BYunC8HOtzw"
   },
   "outputs": [],
   "source": [
    "# lr = 0.00001\n",
    "# Lambda = 0\n",
    "# train_and_test_loop(X_train, y_train, 1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62Qk0mqfOtzy"
   },
   "outputs": [],
   "source": [
    "# lr = 0.00001\n",
    "# Lambda = 1e3\n",
    "# train_and_test_loop(X_train, y_train, 1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PutMxKfyOtz0"
   },
   "outputs": [],
   "source": [
    "# X_train_subset = X_train[0:20]\n",
    "# y_train_subset = y_train[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GfNpfvOBOtz2"
   },
   "outputs": [],
   "source": [
    "# lr = 0.001\n",
    "# Lambda = 0\n",
    "# train_and_test_loop(X_train_subset, y_train_subset, 500, lr, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aGqczQROtz4"
   },
   "outputs": [],
   "source": [
    "# lr = 1e-7\n",
    "# Lambda = 1e-7\n",
    "# train_and_test_loop(X_train, y_train, 20, lr, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNg-lS-hOtz6"
   },
   "outputs": [],
   "source": [
    "# lr = 1e8\n",
    "# Lambda = 1e-7\n",
    "# train_and_test_loop(X_train, y_train, 20, lr, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsDbteGpOtz7"
   },
   "outputs": [],
   "source": [
    "# lr = 1e4\n",
    "# Lambda = 1e-7\n",
    "# train_and_test_loop(X_train, y_train, 20, lr, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svLuFZINOtz9"
   },
   "outputs": [],
   "source": [
    "def train_and_test_loop_ht(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,), activation='relu'))\n",
    "    model.add(Dense(hidden_nodes, activation='relu'))\n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=iterations, batch_size=1000, verbose= 0)\n",
    "    score = model.evaluate(X_train, y_train, verbose=0)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANzqDR8NunFw"
   },
   "outputs": [],
   "source": [
    "global df_Accuracy_Score\n",
    "df_Accuracy_Score = pd.DataFrame()\n",
    "\n",
    "def Score(Model, X_test,y_test, y_labels, Y_pred_cls):\n",
    "    Metrics, Score = ['Accuracy', 'Precision', 'Recall', 'F1 Score'], []      \n",
    "    Score.append(str(model.evaluate(X_test,y_test)[1]))\n",
    "    Score.append(str(precision_score(y_labels, Y_pred_cls, average='macro')))\n",
    "    Score.append(str(recall_score(y_labels,Y_pred_cls, average='macro')))\n",
    "    Score.append(str(f1_score(y_labels,Y_pred_cls, average='macro')))\n",
    "    df_Accuracy_Score['Metrics'], df_Accuracy_Score[Model] = Metrics, Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6QA6JmBOtz_"
   },
   "outputs": [],
   "source": [
    "# for k in range(1,11):\n",
    "#     lr = math.pow(10, np.random.uniform(-4.0, 0.0))\n",
    "#     Lambda = math.pow(10, np.random.uniform(-7,-2))\n",
    "#     best_acc = train_and_test_loop_ht(100, lr, Lambda, False)\n",
    "#     print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fVHJIGIOt0B"
   },
   "outputs": [],
   "source": [
    "# for k in range(1,11):\n",
    "#     lr = np.random.uniform(0.04, 0.05)\n",
    "#     Lambda = math.pow(10, np.random.uniform(-8,-5))\n",
    "#     best_acc = train_and_test_loop_ht(100, lr, Lambda, False)\n",
    "#     print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdUwqnQpPdmf"
   },
   "outputs": [],
   "source": [
    "# for k in range(1,11):\n",
    "#     lr = np.random.uniform(0.045, 0.049)\n",
    "#     Lambda = np.random.uniform(0.000004,0.0000005)\n",
    "#     best_acc = train_and_test_loop_ht(100, lr, Lambda, False)\n",
    "#     print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization - Coarse to fine tuning\n",
    "* Check loss range & accuracy\n",
    "* Overfit a subset of the training data to check if model works\n",
    "* Identify learning rate & regularization lambda upper and lower limits \n",
    "* Hyperparameter tuning\n",
    "* After completing above steps below learning rate & regularization lambda was finalized for first Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IyhPbtrKt9bd",
    "outputId": "2bd32e57-60f3-49bf-d294-8fce0d76a90c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.3040 - accuracy: 0.1183 - val_loss: 2.2831 - val_accuracy: 0.1499\n",
      "Epoch 2/100\n",
      " - 1s - loss: 2.2342 - accuracy: 0.2255 - val_loss: 2.1654 - val_accuracy: 0.3004\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.0127 - accuracy: 0.3620 - val_loss: 1.8365 - val_accuracy: 0.4135\n",
      "Epoch 4/100\n",
      " - 1s - loss: 1.7129 - accuracy: 0.4497 - val_loss: 1.6429 - val_accuracy: 0.4693\n",
      "Epoch 5/100\n",
      " - 1s - loss: 1.5286 - accuracy: 0.5010 - val_loss: 1.5291 - val_accuracy: 0.4819\n",
      "Epoch 6/100\n",
      " - 1s - loss: 1.3412 - accuracy: 0.5732 - val_loss: 1.5754 - val_accuracy: 0.4751\n",
      "Epoch 7/100\n",
      " - 1s - loss: 1.3433 - accuracy: 0.5718 - val_loss: 1.1789 - val_accuracy: 0.6365\n",
      "Epoch 8/100\n",
      " - 1s - loss: 1.1476 - accuracy: 0.6473 - val_loss: 1.0976 - val_accuracy: 0.6604\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.0922 - accuracy: 0.6630 - val_loss: 1.1029 - val_accuracy: 0.6504\n",
      "Epoch 10/100\n",
      " - 1s - loss: 1.0494 - accuracy: 0.6741 - val_loss: 1.0078 - val_accuracy: 0.6943\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.0176 - accuracy: 0.6826 - val_loss: 1.0648 - val_accuracy: 0.6669\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.9800 - accuracy: 0.6965 - val_loss: 0.9688 - val_accuracy: 0.6995\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.9413 - accuracy: 0.7095 - val_loss: 0.9767 - val_accuracy: 0.6973\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.9255 - accuracy: 0.7146 - val_loss: 0.9569 - val_accuracy: 0.7073\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.9081 - accuracy: 0.7188 - val_loss: 0.9194 - val_accuracy: 0.7173\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.8608 - accuracy: 0.7366 - val_loss: 0.8629 - val_accuracy: 0.7380\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.8186 - accuracy: 0.7495 - val_loss: 0.8758 - val_accuracy: 0.7258\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.8038 - accuracy: 0.7518 - val_loss: 0.8225 - val_accuracy: 0.7511\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.8305 - accuracy: 0.7417 - val_loss: 0.8741 - val_accuracy: 0.7323\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.8034 - accuracy: 0.7533 - val_loss: 0.8187 - val_accuracy: 0.7499\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.7514 - accuracy: 0.7696 - val_loss: 0.8051 - val_accuracy: 0.7548\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.7683 - accuracy: 0.7609 - val_loss: 0.8165 - val_accuracy: 0.7486\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.7143 - accuracy: 0.7817 - val_loss: 0.7780 - val_accuracy: 0.7656\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.7249 - accuracy: 0.7778 - val_loss: 0.8417 - val_accuracy: 0.7355\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.7204 - accuracy: 0.7797 - val_loss: 0.7651 - val_accuracy: 0.7685\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.6991 - accuracy: 0.7855 - val_loss: 0.7805 - val_accuracy: 0.7648\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.6742 - accuracy: 0.7935 - val_loss: 0.7776 - val_accuracy: 0.7598\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.6616 - accuracy: 0.7971 - val_loss: 0.7390 - val_accuracy: 0.7798\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.6692 - accuracy: 0.7932 - val_loss: 0.7266 - val_accuracy: 0.7789\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.6607 - accuracy: 0.7970 - val_loss: 0.6973 - val_accuracy: 0.7877\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.6224 - accuracy: 0.8102 - val_loss: 0.6790 - val_accuracy: 0.7948\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.6297 - accuracy: 0.8072 - val_loss: 0.7151 - val_accuracy: 0.7837\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.6306 - accuracy: 0.8052 - val_loss: 0.7203 - val_accuracy: 0.7799\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.5912 - accuracy: 0.8172 - val_loss: 0.7238 - val_accuracy: 0.7804\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.6071 - accuracy: 0.8119 - val_loss: 0.6993 - val_accuracy: 0.7918\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.6028 - accuracy: 0.8155 - val_loss: 0.7108 - val_accuracy: 0.7848\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.5831 - accuracy: 0.8189 - val_loss: 0.7253 - val_accuracy: 0.7808\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.5736 - accuracy: 0.8246 - val_loss: 0.6760 - val_accuracy: 0.8018\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.5685 - accuracy: 0.8252 - val_loss: 0.6477 - val_accuracy: 0.8074\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.5536 - accuracy: 0.8294 - val_loss: 0.6774 - val_accuracy: 0.7979\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.5454 - accuracy: 0.8325 - val_loss: 0.6658 - val_accuracy: 0.8007\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.5296 - accuracy: 0.8362 - val_loss: 0.6358 - val_accuracy: 0.8130\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.5356 - accuracy: 0.8339 - val_loss: 0.6562 - val_accuracy: 0.8055\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.5494 - accuracy: 0.8299 - val_loss: 0.7107 - val_accuracy: 0.7868\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.5326 - accuracy: 0.8345 - val_loss: 0.6670 - val_accuracy: 0.8012\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.5097 - accuracy: 0.8443 - val_loss: 0.6889 - val_accuracy: 0.7973\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.5510 - accuracy: 0.8302 - val_loss: 0.6378 - val_accuracy: 0.8136\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.5033 - accuracy: 0.8474 - val_loss: 0.6390 - val_accuracy: 0.8129\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.4868 - accuracy: 0.8531 - val_loss: 0.6145 - val_accuracy: 0.8214\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.4815 - accuracy: 0.8507 - val_loss: 0.6459 - val_accuracy: 0.8095\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.4692 - accuracy: 0.8572 - val_loss: 0.6660 - val_accuracy: 0.8070\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.5144 - accuracy: 0.8394 - val_loss: 0.6926 - val_accuracy: 0.7976\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.4810 - accuracy: 0.8515 - val_loss: 0.7041 - val_accuracy: 0.7952\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.4723 - accuracy: 0.8532 - val_loss: 0.6399 - val_accuracy: 0.8154\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.4791 - accuracy: 0.8501 - val_loss: 0.6538 - val_accuracy: 0.8090\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.4704 - accuracy: 0.8555 - val_loss: 0.6265 - val_accuracy: 0.8156\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.4679 - accuracy: 0.8557 - val_loss: 0.6287 - val_accuracy: 0.8202\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.4459 - accuracy: 0.8635 - val_loss: 0.6082 - val_accuracy: 0.8262\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.4324 - accuracy: 0.8677 - val_loss: 0.6197 - val_accuracy: 0.8213\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.4348 - accuracy: 0.8660 - val_loss: 0.6042 - val_accuracy: 0.8246\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.4185 - accuracy: 0.8713 - val_loss: 0.6363 - val_accuracy: 0.8119\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.4411 - accuracy: 0.8643 - val_loss: 0.6008 - val_accuracy: 0.8298\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4320 - accuracy: 0.8663 - val_loss: 0.6225 - val_accuracy: 0.8201\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.4261 - accuracy: 0.8683 - val_loss: 0.6350 - val_accuracy: 0.8193\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.4102 - accuracy: 0.8735 - val_loss: 0.6236 - val_accuracy: 0.8246\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.4099 - accuracy: 0.8735 - val_loss: 0.6382 - val_accuracy: 0.8170\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.4107 - accuracy: 0.8728 - val_loss: 0.6374 - val_accuracy: 0.8199\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.4281 - accuracy: 0.8650 - val_loss: 0.6345 - val_accuracy: 0.8183\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3967 - accuracy: 0.8785 - val_loss: 0.6436 - val_accuracy: 0.8168\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3997 - accuracy: 0.8758 - val_loss: 0.6212 - val_accuracy: 0.8206\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3925 - accuracy: 0.8794 - val_loss: 0.6504 - val_accuracy: 0.8155\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3890 - accuracy: 0.8797 - val_loss: 0.6464 - val_accuracy: 0.8206\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3882 - accuracy: 0.8798 - val_loss: 0.6141 - val_accuracy: 0.8314\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3817 - accuracy: 0.8814 - val_loss: 0.6274 - val_accuracy: 0.8190\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3829 - accuracy: 0.8802 - val_loss: 0.6056 - val_accuracy: 0.8321\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3803 - accuracy: 0.8818 - val_loss: 0.6033 - val_accuracy: 0.8346\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3629 - accuracy: 0.8878 - val_loss: 0.6132 - val_accuracy: 0.8319\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3612 - accuracy: 0.8876 - val_loss: 0.6132 - val_accuracy: 0.8287\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3619 - accuracy: 0.8880 - val_loss: 0.6031 - val_accuracy: 0.8294\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3483 - accuracy: 0.8922 - val_loss: 0.6017 - val_accuracy: 0.8343\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3437 - accuracy: 0.8932 - val_loss: 0.5992 - val_accuracy: 0.8317\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3570 - accuracy: 0.8873 - val_loss: 0.6227 - val_accuracy: 0.8329\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3450 - accuracy: 0.8923 - val_loss: 0.6382 - val_accuracy: 0.8201\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3382 - accuracy: 0.8947 - val_loss: 0.6074 - val_accuracy: 0.8356\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3523 - accuracy: 0.8908 - val_loss: 0.6133 - val_accuracy: 0.8327\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3360 - accuracy: 0.8945 - val_loss: 0.5973 - val_accuracy: 0.8355\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3323 - accuracy: 0.8957 - val_loss: 0.6188 - val_accuracy: 0.8318\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3591 - accuracy: 0.8882 - val_loss: 0.6249 - val_accuracy: 0.8294\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3330 - accuracy: 0.8955 - val_loss: 0.6201 - val_accuracy: 0.8312\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3064 - accuracy: 0.9054 - val_loss: 0.6094 - val_accuracy: 0.8344\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3067 - accuracy: 0.9056 - val_loss: 0.6023 - val_accuracy: 0.8357\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3049 - accuracy: 0.9052 - val_loss: 0.6026 - val_accuracy: 0.8383\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2969 - accuracy: 0.9092 - val_loss: 0.6252 - val_accuracy: 0.8282\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3179 - accuracy: 0.9003 - val_loss: 0.6340 - val_accuracy: 0.8312\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3088 - accuracy: 0.9042 - val_loss: 0.6203 - val_accuracy: 0.8345\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3028 - accuracy: 0.9071 - val_loss: 0.6506 - val_accuracy: 0.8276\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3157 - accuracy: 0.9016 - val_loss: 0.6343 - val_accuracy: 0.8315\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2997 - accuracy: 0.9068 - val_loss: 0.6264 - val_accuracy: 0.8319\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3043 - accuracy: 0.9041 - val_loss: 0.6295 - val_accuracy: 0.8348\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2849 - accuracy: 0.9108 - val_loss: 0.6074 - val_accuracy: 0.8398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc67e8de320>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.04765542214558115\n",
    "Lambda = 2.913984989218504e-06\n",
    "hidden_nodes = 256\n",
    "output_nodes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_nodes, input_shape=(1024,), activation='relu'))\n",
    "model.add(Dense(hidden_nodes, activation='relu'))\n",
    "model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "\n",
    "sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_split = 0.20, epochs=100, shuffle = True, batch_size=1000, verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "SfVwwnN7CgF0",
    "outputId": "9f5acebc-234b-4c2a-dfc9-e5608ef29cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 330,762\n",
      "Trainable params: 330,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ZfdjOZGrA0oU",
    "outputId": "8f4bdedd-dab1-4495-f997-855f398f326a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 40us/step\n",
      "Test accuracy:  0.8357222080230713\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "CaCx5rVSJBHx",
    "outputId": "f8f17a30-0036-4367-9123-6564d8ace1ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 43us/step\n",
      "Accuracy: 0.8357222080230713\n",
      "Recall_score: 0.8355198542572433\n",
      "Precision_score: 0.8379401971779197\n",
      "F-score: 0.8358035411444584\n",
      "18000/18000 [==============================] - 1s 42us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1638,   16,    7,   25,   16,    5,   33,   13,   25,   36],\n",
       "       [  30, 1558,   20,   42,   38,    6,   32,   53,   33,   16],\n",
       "       [  31,   18, 1484,   63,   25,   17,   10,   68,   35,   52],\n",
       "       [  18,   23,   17, 1427,    7,   83,   41,   33,   37,   33],\n",
       "       [  31,   38,   21,   33, 1533,   12,   51,   12,   43,   38],\n",
       "       [  29,   10,    8,  128,    8, 1386,   83,    7,   63,   46],\n",
       "       [  50,   17,   14,   24,   23,   40, 1545,   10,   90,   19],\n",
       "       [  34,   63,   28,   42,   10,    6,   14, 1575,   12,   24],\n",
       "       [  33,   24,   21,   70,   13,   27,   97,   13, 1467,   47],\n",
       "       [  89,   23,   17,   56,   18,   56,   26,   25,   64, 1430]])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_cls = model.predict_classes(X_test, batch_size=200, verbose=0)\n",
    "y_labels = np.argmax(y_test, axis=1)\n",
    "print('Accuracy: '+ str(model.evaluate(X_test,y_test)[1]))\n",
    "print('Recall_score: ' + str(recall_score(y_labels,Y_pred_cls, average='macro')))\n",
    "print('Precision_score: ' + str(precision_score(y_labels, Y_pred_cls, average='macro')))\n",
    "print('F-score: ' + str(f1_score(y_labels,Y_pred_cls, average='macro')))\n",
    "Score('NN', X_test,y_test, y_labels, Y_pred_cls)\n",
    "confusion_matrix(y_labels, Y_pred_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KuLzgFBgunF_"
   },
   "source": [
    "#### Task: Implementing batch normalization for training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_oCMqbnW5BUq"
   },
   "outputs": [],
   "source": [
    "def train_and_test_loop_ht(iterations, lr, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,), kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(output_nodes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = lr)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=iterations, batch_size=1000, verbose= 0)\n",
    "    score = model.evaluate(X_train, y_train, verbose=0)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AAV2A_16Ot0D"
   },
   "outputs": [],
   "source": [
    "# for k in range(1,11):\n",
    "#     lr = math.pow(10, np.random.uniform(-4.0, -1.0))\n",
    "#     best_acc = train_and_test_loop_ht(100, lr, False)\n",
    "#     print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}\\n\".format(k, 10, best_acc, lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Batch Normalization & Adam optimizer applied \n",
    "* Multiple rounds of hyperparameter tuning completed\n",
    "* After completing above steps below learning rate was finalized for second Neural Network with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KO8GObR_2Der",
    "outputId": "74af001b-61c8-4815-d2e5-7f559ae99b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.7519 - accuracy: 0.4173 - val_loss: 2.6617 - val_accuracy: 0.2676\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.0370 - accuracy: 0.6762 - val_loss: 1.4875 - val_accuracy: 0.5290\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.8608 - accuracy: 0.7319 - val_loss: 1.3706 - val_accuracy: 0.5570\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.7362 - accuracy: 0.7709 - val_loss: 1.4252 - val_accuracy: 0.5719\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.6473 - accuracy: 0.7979 - val_loss: 1.3231 - val_accuracy: 0.6031\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.5953 - accuracy: 0.8140 - val_loss: 1.3795 - val_accuracy: 0.5727\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.5692 - accuracy: 0.8222 - val_loss: 1.5360 - val_accuracy: 0.5790\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.5254 - accuracy: 0.8361 - val_loss: 1.5399 - val_accuracy: 0.5964\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.4953 - accuracy: 0.8434 - val_loss: 1.2605 - val_accuracy: 0.6119\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.4507 - accuracy: 0.8585 - val_loss: 1.5356 - val_accuracy: 0.6018\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.4474 - accuracy: 0.8593 - val_loss: 1.0155 - val_accuracy: 0.6923\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.4063 - accuracy: 0.8721 - val_loss: 1.1760 - val_accuracy: 0.6696\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.3781 - accuracy: 0.8803 - val_loss: 2.0739 - val_accuracy: 0.5577\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.3618 - accuracy: 0.8855 - val_loss: 1.1041 - val_accuracy: 0.6694\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.3570 - accuracy: 0.8853 - val_loss: 2.3230 - val_accuracy: 0.5323\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3210 - accuracy: 0.8985 - val_loss: 1.0131 - val_accuracy: 0.7186\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.2911 - accuracy: 0.9073 - val_loss: 1.4815 - val_accuracy: 0.6676\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.2965 - accuracy: 0.9042 - val_loss: 1.2638 - val_accuracy: 0.6871\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.2878 - accuracy: 0.9083 - val_loss: 2.0254 - val_accuracy: 0.6124\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.2688 - accuracy: 0.9149 - val_loss: 1.9736 - val_accuracy: 0.6218\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.2579 - accuracy: 0.9168 - val_loss: 1.5519 - val_accuracy: 0.6289\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.2500 - accuracy: 0.9185 - val_loss: 1.6358 - val_accuracy: 0.6298\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.2182 - accuracy: 0.9317 - val_loss: 1.0998 - val_accuracy: 0.7257\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.1997 - accuracy: 0.9366 - val_loss: 1.1893 - val_accuracy: 0.7011\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.2099 - accuracy: 0.9320 - val_loss: 1.1114 - val_accuracy: 0.7333\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.1873 - accuracy: 0.9409 - val_loss: 1.3688 - val_accuracy: 0.6862\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.1802 - accuracy: 0.9418 - val_loss: 1.6258 - val_accuracy: 0.6255\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.1744 - accuracy: 0.9442 - val_loss: 1.2457 - val_accuracy: 0.7258\n",
      "Epoch 29/100\n",
      " - 2s - loss: 0.1743 - accuracy: 0.9442 - val_loss: 1.4031 - val_accuracy: 0.6929\n",
      "Epoch 30/100\n",
      " - 2s - loss: 0.1566 - accuracy: 0.9500 - val_loss: 1.1973 - val_accuracy: 0.7170\n",
      "Epoch 31/100\n",
      " - 2s - loss: 0.1549 - accuracy: 0.9502 - val_loss: 1.4474 - val_accuracy: 0.7033\n",
      "Epoch 32/100\n",
      " - 2s - loss: 0.1285 - accuracy: 0.9606 - val_loss: 1.2313 - val_accuracy: 0.7407\n",
      "Epoch 33/100\n",
      " - 2s - loss: 0.1295 - accuracy: 0.9592 - val_loss: 1.4470 - val_accuracy: 0.7033\n",
      "Epoch 34/100\n",
      " - 2s - loss: 0.1437 - accuracy: 0.9539 - val_loss: 1.5835 - val_accuracy: 0.6760\n",
      "Epoch 35/100\n",
      " - 2s - loss: 0.1405 - accuracy: 0.9554 - val_loss: 1.7313 - val_accuracy: 0.6854\n",
      "Epoch 36/100\n",
      " - 2s - loss: 0.1287 - accuracy: 0.9585 - val_loss: 2.0792 - val_accuracy: 0.6305\n",
      "Epoch 37/100\n",
      " - 2s - loss: 0.1202 - accuracy: 0.9615 - val_loss: 1.5011 - val_accuracy: 0.7043\n",
      "Epoch 38/100\n",
      " - 2s - loss: 0.1048 - accuracy: 0.9676 - val_loss: 1.2227 - val_accuracy: 0.7444\n",
      "Epoch 39/100\n",
      " - 2s - loss: 0.1050 - accuracy: 0.9669 - val_loss: 1.6207 - val_accuracy: 0.6955\n",
      "Epoch 40/100\n",
      " - 2s - loss: 0.1140 - accuracy: 0.9635 - val_loss: 1.4618 - val_accuracy: 0.7019\n",
      "Epoch 41/100\n",
      " - 2s - loss: 0.0996 - accuracy: 0.9679 - val_loss: 1.5441 - val_accuracy: 0.7010\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.0961 - accuracy: 0.9693 - val_loss: 1.3043 - val_accuracy: 0.7415\n",
      "Epoch 43/100\n",
      " - 2s - loss: 0.0799 - accuracy: 0.9758 - val_loss: 1.3175 - val_accuracy: 0.7517\n",
      "Epoch 44/100\n",
      " - 2s - loss: 0.0768 - accuracy: 0.9755 - val_loss: 1.5744 - val_accuracy: 0.7302\n",
      "Epoch 45/100\n",
      " - 2s - loss: 0.0814 - accuracy: 0.9740 - val_loss: 1.7503 - val_accuracy: 0.7219\n",
      "Epoch 46/100\n",
      " - 2s - loss: 0.0723 - accuracy: 0.9774 - val_loss: 1.7259 - val_accuracy: 0.7350\n",
      "Epoch 47/100\n",
      " - 2s - loss: 0.0803 - accuracy: 0.9734 - val_loss: 1.7224 - val_accuracy: 0.7146\n",
      "Epoch 48/100\n",
      " - 2s - loss: 0.0798 - accuracy: 0.9740 - val_loss: 1.6142 - val_accuracy: 0.7239\n",
      "Epoch 49/100\n",
      " - 2s - loss: 0.0984 - accuracy: 0.9675 - val_loss: 1.6112 - val_accuracy: 0.6886\n",
      "Epoch 50/100\n",
      " - 2s - loss: 0.0861 - accuracy: 0.9711 - val_loss: 1.1916 - val_accuracy: 0.7631\n",
      "Epoch 51/100\n",
      " - 2s - loss: 0.0694 - accuracy: 0.9779 - val_loss: 1.5457 - val_accuracy: 0.7330\n",
      "Epoch 52/100\n",
      " - 2s - loss: 0.0691 - accuracy: 0.9784 - val_loss: 1.6324 - val_accuracy: 0.7110\n",
      "Epoch 53/100\n",
      " - 2s - loss: 0.0614 - accuracy: 0.9810 - val_loss: 1.7519 - val_accuracy: 0.7144\n",
      "Epoch 54/100\n",
      " - 2s - loss: 0.0528 - accuracy: 0.9838 - val_loss: 1.4541 - val_accuracy: 0.7443\n",
      "Epoch 55/100\n",
      " - 2s - loss: 0.0475 - accuracy: 0.9857 - val_loss: 1.2224 - val_accuracy: 0.7787\n",
      "Epoch 56/100\n",
      " - 2s - loss: 0.0397 - accuracy: 0.9889 - val_loss: 1.5647 - val_accuracy: 0.7551\n",
      "Epoch 57/100\n",
      " - 2s - loss: 0.0476 - accuracy: 0.9860 - val_loss: 1.5273 - val_accuracy: 0.7414\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.0564 - accuracy: 0.9822 - val_loss: 1.6763 - val_accuracy: 0.7150\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.0703 - accuracy: 0.9762 - val_loss: 1.8427 - val_accuracy: 0.7306\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.0736 - accuracy: 0.9746 - val_loss: 2.4837 - val_accuracy: 0.6715\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.0884 - accuracy: 0.9712 - val_loss: 2.7615 - val_accuracy: 0.6350\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.0789 - accuracy: 0.9736 - val_loss: 2.3051 - val_accuracy: 0.6914\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.0654 - accuracy: 0.9782 - val_loss: 1.5058 - val_accuracy: 0.7463\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.0543 - accuracy: 0.9823 - val_loss: 1.9295 - val_accuracy: 0.6908\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.0441 - accuracy: 0.9870 - val_loss: 1.4628 - val_accuracy: 0.7625\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.0395 - accuracy: 0.9880 - val_loss: 1.4347 - val_accuracy: 0.7625\n",
      "Epoch 67/100\n",
      " - 2s - loss: 0.0360 - accuracy: 0.9896 - val_loss: 1.4513 - val_accuracy: 0.7633\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.0493 - accuracy: 0.9843 - val_loss: 1.7684 - val_accuracy: 0.7373\n",
      "Epoch 69/100\n",
      " - 2s - loss: 0.0513 - accuracy: 0.9836 - val_loss: 1.9320 - val_accuracy: 0.7156\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.0782 - accuracy: 0.9739 - val_loss: 2.2578 - val_accuracy: 0.6938\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.0606 - accuracy: 0.9789 - val_loss: 1.4399 - val_accuracy: 0.7687\n",
      "Epoch 72/100\n",
      " - 2s - loss: 0.0379 - accuracy: 0.9882 - val_loss: 2.4836 - val_accuracy: 0.6998\n",
      "Epoch 73/100\n",
      " - 2s - loss: 0.0377 - accuracy: 0.9886 - val_loss: 2.2437 - val_accuracy: 0.7043\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.0343 - accuracy: 0.9900 - val_loss: 1.4820 - val_accuracy: 0.7736\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.0217 - accuracy: 0.9946 - val_loss: 1.3797 - val_accuracy: 0.7863\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.0170 - accuracy: 0.9959 - val_loss: 1.5406 - val_accuracy: 0.7767\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.0153 - accuracy: 0.9967 - val_loss: 1.2834 - val_accuracy: 0.8068\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.0175 - accuracy: 0.9955 - val_loss: 1.5217 - val_accuracy: 0.7608\n",
      "Epoch 79/100\n",
      " - 2s - loss: 0.0207 - accuracy: 0.9944 - val_loss: 1.8836 - val_accuracy: 0.7464\n",
      "Epoch 80/100\n",
      " - 2s - loss: 0.0250 - accuracy: 0.9927 - val_loss: 1.6553 - val_accuracy: 0.7651\n",
      "Epoch 81/100\n",
      " - 2s - loss: 0.0265 - accuracy: 0.9924 - val_loss: 1.9014 - val_accuracy: 0.7607\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.0356 - accuracy: 0.9884 - val_loss: 2.3386 - val_accuracy: 0.6871\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.0420 - accuracy: 0.9867 - val_loss: 2.1133 - val_accuracy: 0.7107\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0452 - accuracy: 0.9847 - val_loss: 2.1098 - val_accuracy: 0.7300\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.0717 - accuracy: 0.9747 - val_loss: 2.2248 - val_accuracy: 0.6843\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.0892 - accuracy: 0.9687 - val_loss: 2.2943 - val_accuracy: 0.7181\n",
      "Epoch 87/100\n",
      " - 2s - loss: 0.0811 - accuracy: 0.9716 - val_loss: 3.8350 - val_accuracy: 0.6050\n",
      "Epoch 88/100\n",
      " - 2s - loss: 0.0923 - accuracy: 0.9680 - val_loss: 2.9597 - val_accuracy: 0.6713\n",
      "Epoch 89/100\n",
      " - 2s - loss: 0.0836 - accuracy: 0.9719 - val_loss: 2.1465 - val_accuracy: 0.7074\n",
      "Epoch 90/100\n",
      " - 2s - loss: 0.0549 - accuracy: 0.9810 - val_loss: 1.9951 - val_accuracy: 0.7257\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.0385 - accuracy: 0.9881 - val_loss: 1.6833 - val_accuracy: 0.7520\n",
      "Epoch 92/100\n",
      " - 2s - loss: 0.0246 - accuracy: 0.9926 - val_loss: 1.6566 - val_accuracy: 0.7656\n",
      "Epoch 93/100\n",
      " - 2s - loss: 0.0200 - accuracy: 0.9941 - val_loss: 1.5825 - val_accuracy: 0.7804\n",
      "Epoch 94/100\n",
      " - 2s - loss: 0.0196 - accuracy: 0.9949 - val_loss: 2.0169 - val_accuracy: 0.7306\n",
      "Epoch 95/100\n",
      " - 2s - loss: 0.0199 - accuracy: 0.9944 - val_loss: 1.4726 - val_accuracy: 0.7950\n",
      "Epoch 96/100\n",
      " - 2s - loss: 0.0121 - accuracy: 0.9974 - val_loss: 1.5545 - val_accuracy: 0.7907\n",
      "Epoch 97/100\n",
      " - 2s - loss: 0.0080 - accuracy: 0.9987 - val_loss: 1.3753 - val_accuracy: 0.8090\n",
      "Epoch 98/100\n",
      " - 2s - loss: 0.0069 - accuracy: 0.9989 - val_loss: 1.3985 - val_accuracy: 0.8020\n",
      "Epoch 99/100\n",
      " - 2s - loss: 0.0059 - accuracy: 0.9990 - val_loss: 1.5091 - val_accuracy: 0.7888\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.0039 - accuracy: 0.9996 - val_loss: 1.3480 - val_accuracy: 0.8213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc677e58898>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.006217387305341968\n",
    "hidden_nodes = 256\n",
    "output_nodes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_nodes, input_shape=(1024,), kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(hidden_nodes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_nodes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr = learning_rate)\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_split = 0.20, epochs=100, shuffle = True, batch_size=1000, verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "AE8AF2RJCbJ_",
    "outputId": "a9d9338f-5684-4a7d-dbe9-f582425a5bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 332,810\n",
      "Trainable params: 331,786\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "AKU4pxNPAGfJ",
    "outputId": "fd8ad126-7938-48d6-c6fc-1b1197c1bf90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 44us/step\n",
      "Test accuracy:  0.8146666884422302\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "TAthrYprAM1L",
    "outputId": "a573f9e2-598b-4ead-e6b1-5fb30247909b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 44us/step\n",
      "Accuracy: 0.8146666884422302\n",
      "Recall_score: 0.8146233095623353\n",
      "Precision_score: 0.8220514983678102\n",
      "F-score: 0.815625369039197\n",
      "18000/18000 [==============================] - 1s 44us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1633,   24,    6,   27,   12,    9,   24,   10,   21,   48],\n",
       "       [  56, 1541,    7,   67,   41,    9,   23,   28,   27,   29],\n",
       "       [  34,   40, 1382,  123,   31,   21,    6,   57,   44,   65],\n",
       "       [  29,   36,   18, 1405,   12,   96,   23,   22,   37,   41],\n",
       "       [  57,   69,   16,   48, 1487,   15,   48,    6,   21,   45],\n",
       "       [  33,   18,    8,  130,   10, 1417,   60,    7,   34,   51],\n",
       "       [ 103,   22,    9,   46,   26,   55, 1436,    7,   96,   32],\n",
       "       [  45,   87,   10,   77,   11,    7,   13, 1511,   15,   32],\n",
       "       [  76,   33,    9,   81,   12,   36,   74,    3, 1404,   84],\n",
       "       [ 109,   26,    9,   79,   18,   34,   21,   18,   42, 1448]])"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_cls = model.predict_classes(X_test, batch_size=200, verbose=0)\n",
    "y_labels = np.argmax(y_test, axis=1)\n",
    "print('Accuracy: '+ str(model.evaluate(X_test,y_test)[1]))\n",
    "print('Recall_score: ' + str(recall_score(y_labels,Y_pred_cls, average='macro')))\n",
    "print('Precision_score: ' + str(precision_score(y_labels, Y_pred_cls, average='macro')))\n",
    "print('F-score: ' + str(f1_score(y_labels,Y_pred_cls, average='macro')))\n",
    "Score('NNBN', X_test,y_test, y_labels, Y_pred_cls)\n",
    "confusion_matrix(y_labels, Y_pred_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2vvvnxCHunGK"
   },
   "source": [
    "#### Task: Since model is overfitting in both cases implementing data augmentation to improve performance\n",
    "* Image intensity rescale: Stretching or shrinking image intensity levels\n",
    "* Filter Otsu Threshold: Mask threshold value based on Otsu's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_c-61-O_Otzk"
   },
   "outputs": [],
   "source": [
    "from skimage import img_as_float, exposure, filters\n",
    "def data_aug_X(X):\n",
    "    Y, Z = np.zeros(shape=(0, 1024)), np.zeros(shape=(0, 1024))\n",
    "    for img in X:\n",
    "        p2, p98 = np.percentile(img, (2, 98))\n",
    "        img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "        val = filters.threshold_otsu(img)\n",
    "        mask = img < val\n",
    "        Y = np.append(Y, [img_rescale], axis = 0)\n",
    "        Z = np.append(Z, [mask.astype(int)], axis = 0)\n",
    "    X = np.append(X, Y, axis = 0)\n",
    "    X = np.append(X, Z, axis = 0)\n",
    "    return X\n",
    "\n",
    "def data_aug_y(y):\n",
    "    Y = np.append(y, y, axis = 0)\n",
    "    y = np.append(Y, y, axis = 0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TFb1ZWGEOtzm",
    "outputId": "10a42902-ab25-4bb7-9d40-686a06f93f30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126000, 1024) (18000, 1024) (126000, 10) (18000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_aug_X(X_train)\n",
    "y_train = data_aug_y(y_train)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "da1CP_AjOtzo",
    "outputId": "3ed988cc-58d8-41c5-f135-67cbb218f492"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[42000].reshape(32, 32), cmap='gray')\n",
    "plt.show()\n",
    "print('Label: ', y_train[42000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "OPJDCr-wOtzq",
    "outputId": "ba3c9987-fb9f-47cf-93f8-ec9587875e41"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[84000].reshape(32, 32), cmap='gray')\n",
    "plt.show()\n",
    "print('Label: ', y_train[84000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJvk4WJLKCs0"
   },
   "outputs": [],
   "source": [
    "def train_and_test_loop_ht(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,), activation='relu'))\n",
    "    model.add(Dense(hidden_nodes, activation='relu'))\n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=iterations, batch_size=1000, verbose= 0)\n",
    "    score = model.evaluate(X_train, y_train, verbose=0)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKi6IeUAKCs3"
   },
   "outputs": [],
   "source": [
    "# for k in range(1,11):\n",
    "#     lr = math.pow(10, np.random.uniform(-4.0, 0.0))\n",
    "#     Lambda = math.pow(10, np.random.uniform(-7,-2))\n",
    "#     best_acc = train_and_test_loop_ht(100, lr, Lambda, False)\n",
    "#     print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "riFkd1kLKCs5"
   },
   "outputs": [],
   "source": [
    "# for k in range(1,11):\n",
    "#     lr = math.pow(10, np.random.uniform(-3.0, -1.0))\n",
    "#     Lambda = math.pow(10, np.random.uniform(-7,-4))\n",
    "#     best_acc = train_and_test_loop_ht(100, lr, Lambda, False)\n",
    "#     print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1YIkCYbKCs6"
   },
   "outputs": [],
   "source": [
    "# for k in range(1,11):\n",
    "#     lr = np.random.uniform(0.05, 0.07)\n",
    "#     Lambda = math.pow(10, np.random.uniform(-6,-4))\n",
    "#     best_acc = train_and_test_loop_ht(100, lr, Lambda, False)\n",
    "#     print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization - Coarse to fine tuning for data augmented model\n",
    "* Check loss range & accuracy\n",
    "* Overfit a subset of the training data to check if model works\n",
    "* Identify learning rate & regularization lambda upper and lower limits \n",
    "* Hyperparameter tuning\n",
    "* After completing above steps below learning rate & regularization lambda was finalized for third Neural Network with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UpP85Q2FKCs8",
    "outputId": "bf3aecd7-21d6-4496-babc-1e6757b07a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100800 samples, validate on 25200 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.8184 - accuracy: 0.3984 - val_loss: 1.2582 - val_accuracy: 0.6229\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.1252 - accuracy: 0.6651 - val_loss: 1.0713 - val_accuracy: 0.6917\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.9451 - accuracy: 0.7244 - val_loss: 0.9784 - val_accuracy: 0.7318\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.8233 - accuracy: 0.7636 - val_loss: 0.8998 - val_accuracy: 0.7514\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.7512 - accuracy: 0.7855 - val_loss: 0.8850 - val_accuracy: 0.7675\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.6917 - accuracy: 0.8023 - val_loss: 0.8894 - val_accuracy: 0.7726\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.6585 - accuracy: 0.8111 - val_loss: 0.8743 - val_accuracy: 0.7788\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.6143 - accuracy: 0.8238 - val_loss: 0.8463 - val_accuracy: 0.7850\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.5783 - accuracy: 0.8346 - val_loss: 0.8678 - val_accuracy: 0.7855\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.5506 - accuracy: 0.8426 - val_loss: 0.8439 - val_accuracy: 0.7911\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.5255 - accuracy: 0.8479 - val_loss: 0.8517 - val_accuracy: 0.7889\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.5042 - accuracy: 0.8530 - val_loss: 0.8525 - val_accuracy: 0.7884\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.4778 - accuracy: 0.8605 - val_loss: 0.8773 - val_accuracy: 0.7904\n",
      "Epoch 14/100\n",
      " - 4s - loss: 0.4821 - accuracy: 0.8590 - val_loss: 0.9038 - val_accuracy: 0.7868\n",
      "Epoch 15/100\n",
      " - 4s - loss: 0.4509 - accuracy: 0.8682 - val_loss: 0.8794 - val_accuracy: 0.7971\n",
      "Epoch 16/100\n",
      " - 4s - loss: 0.4435 - accuracy: 0.8684 - val_loss: 0.9054 - val_accuracy: 0.7946\n",
      "Epoch 17/100\n",
      " - 4s - loss: 0.4157 - accuracy: 0.8789 - val_loss: 0.9206 - val_accuracy: 0.7939\n",
      "Epoch 18/100\n",
      " - 4s - loss: 0.4072 - accuracy: 0.8806 - val_loss: 0.9522 - val_accuracy: 0.7928\n",
      "Epoch 19/100\n",
      " - 4s - loss: 0.3989 - accuracy: 0.8814 - val_loss: 0.9315 - val_accuracy: 0.7947\n",
      "Epoch 20/100\n",
      " - 4s - loss: 0.3800 - accuracy: 0.8870 - val_loss: 0.9565 - val_accuracy: 0.7947\n",
      "Epoch 21/100\n",
      " - 4s - loss: 0.3728 - accuracy: 0.8885 - val_loss: 0.9828 - val_accuracy: 0.7931\n",
      "Epoch 22/100\n",
      " - 4s - loss: 0.3585 - accuracy: 0.8940 - val_loss: 0.9808 - val_accuracy: 0.7965\n",
      "Epoch 23/100\n",
      " - 4s - loss: 0.3401 - accuracy: 0.8995 - val_loss: 1.0180 - val_accuracy: 0.7923\n",
      "Epoch 24/100\n",
      " - 4s - loss: 0.3402 - accuracy: 0.8988 - val_loss: 1.0391 - val_accuracy: 0.7927\n",
      "Epoch 25/100\n",
      " - 4s - loss: 0.3321 - accuracy: 0.9005 - val_loss: 1.0497 - val_accuracy: 0.7896\n",
      "Epoch 26/100\n",
      " - 4s - loss: 0.3167 - accuracy: 0.9071 - val_loss: 1.0566 - val_accuracy: 0.7972\n",
      "Epoch 27/100\n",
      " - 4s - loss: 0.3057 - accuracy: 0.9084 - val_loss: 1.0930 - val_accuracy: 0.7902\n",
      "Epoch 28/100\n",
      " - 4s - loss: 0.3023 - accuracy: 0.9103 - val_loss: 1.1236 - val_accuracy: 0.7858\n",
      "Epoch 29/100\n",
      " - 4s - loss: 0.2922 - accuracy: 0.9138 - val_loss: 1.1428 - val_accuracy: 0.7899\n",
      "Epoch 30/100\n",
      " - 4s - loss: 0.2812 - accuracy: 0.9167 - val_loss: 1.1492 - val_accuracy: 0.7947\n",
      "Epoch 31/100\n",
      " - 4s - loss: 0.2627 - accuracy: 0.9224 - val_loss: 1.1636 - val_accuracy: 0.7929\n",
      "Epoch 32/100\n",
      " - 4s - loss: 0.2586 - accuracy: 0.9235 - val_loss: 1.1822 - val_accuracy: 0.7921\n",
      "Epoch 33/100\n",
      " - 4s - loss: 0.2636 - accuracy: 0.9216 - val_loss: 1.2150 - val_accuracy: 0.7888\n",
      "Epoch 34/100\n",
      " - 4s - loss: 0.2533 - accuracy: 0.9242 - val_loss: 1.2555 - val_accuracy: 0.7899\n",
      "Epoch 35/100\n",
      " - 4s - loss: 0.2383 - accuracy: 0.9300 - val_loss: 1.2581 - val_accuracy: 0.7891\n",
      "Epoch 36/100\n",
      " - 4s - loss: 0.2333 - accuracy: 0.9314 - val_loss: 1.2747 - val_accuracy: 0.7906\n",
      "Epoch 37/100\n",
      " - 4s - loss: 0.2266 - accuracy: 0.9345 - val_loss: 1.3174 - val_accuracy: 0.7868\n",
      "Epoch 38/100\n",
      " - 4s - loss: 0.2260 - accuracy: 0.9333 - val_loss: 1.3141 - val_accuracy: 0.7937\n",
      "Epoch 39/100\n",
      " - 4s - loss: 0.2217 - accuracy: 0.9337 - val_loss: 1.3700 - val_accuracy: 0.7922\n",
      "Epoch 40/100\n",
      " - 4s - loss: 0.2169 - accuracy: 0.9361 - val_loss: 1.3877 - val_accuracy: 0.7894\n",
      "Epoch 41/100\n",
      " - 4s - loss: 0.2093 - accuracy: 0.9389 - val_loss: 1.4103 - val_accuracy: 0.7899\n",
      "Epoch 42/100\n",
      " - 4s - loss: 0.1977 - accuracy: 0.9431 - val_loss: 1.4491 - val_accuracy: 0.7880\n",
      "Epoch 43/100\n",
      " - 4s - loss: 0.2020 - accuracy: 0.9398 - val_loss: 1.4554 - val_accuracy: 0.7873\n",
      "Epoch 44/100\n",
      " - 4s - loss: 0.1911 - accuracy: 0.9445 - val_loss: 1.4808 - val_accuracy: 0.7870\n",
      "Epoch 45/100\n",
      " - 4s - loss: 0.1848 - accuracy: 0.9458 - val_loss: 1.5232 - val_accuracy: 0.7852\n",
      "Epoch 46/100\n",
      " - 4s - loss: 0.1702 - accuracy: 0.9512 - val_loss: 1.5220 - val_accuracy: 0.7866\n",
      "Epoch 47/100\n",
      " - 4s - loss: 0.1822 - accuracy: 0.9463 - val_loss: 1.5852 - val_accuracy: 0.7853\n",
      "Epoch 48/100\n",
      " - 4s - loss: 0.1725 - accuracy: 0.9496 - val_loss: 1.5875 - val_accuracy: 0.7856\n",
      "Epoch 49/100\n",
      " - 4s - loss: 0.1637 - accuracy: 0.9532 - val_loss: 1.5795 - val_accuracy: 0.7882\n",
      "Epoch 50/100\n",
      " - 4s - loss: 0.1675 - accuracy: 0.9517 - val_loss: 1.6239 - val_accuracy: 0.7871\n",
      "Epoch 51/100\n",
      " - 4s - loss: 0.1562 - accuracy: 0.9556 - val_loss: 1.6569 - val_accuracy: 0.7875\n",
      "Epoch 52/100\n",
      " - 4s - loss: 0.1465 - accuracy: 0.9596 - val_loss: 1.6926 - val_accuracy: 0.7836\n",
      "Epoch 53/100\n",
      " - 4s - loss: 0.1439 - accuracy: 0.9599 - val_loss: 1.7348 - val_accuracy: 0.7884\n",
      "Epoch 54/100\n",
      " - 4s - loss: 0.1524 - accuracy: 0.9569 - val_loss: 1.7323 - val_accuracy: 0.7862\n",
      "Epoch 55/100\n",
      " - 4s - loss: 0.1442 - accuracy: 0.9596 - val_loss: 1.7870 - val_accuracy: 0.7824\n",
      "Epoch 56/100\n",
      " - 4s - loss: 0.1452 - accuracy: 0.9584 - val_loss: 1.7945 - val_accuracy: 0.7867\n",
      "Epoch 57/100\n",
      " - 4s - loss: 0.1361 - accuracy: 0.9624 - val_loss: 1.7918 - val_accuracy: 0.7859\n",
      "Epoch 58/100\n",
      " - 4s - loss: 0.1306 - accuracy: 0.9647 - val_loss: 1.8473 - val_accuracy: 0.7856\n",
      "Epoch 59/100\n",
      " - 4s - loss: 0.1275 - accuracy: 0.9658 - val_loss: 1.8347 - val_accuracy: 0.7860\n",
      "Epoch 60/100\n",
      " - 4s - loss: 0.1460 - accuracy: 0.9580 - val_loss: 1.8596 - val_accuracy: 0.7874\n",
      "Epoch 61/100\n",
      " - 4s - loss: 0.1345 - accuracy: 0.9621 - val_loss: 1.9132 - val_accuracy: 0.7862\n",
      "Epoch 62/100\n",
      " - 4s - loss: 0.1230 - accuracy: 0.9667 - val_loss: 1.9268 - val_accuracy: 0.7862\n",
      "Epoch 63/100\n",
      " - 4s - loss: 0.1326 - accuracy: 0.9626 - val_loss: 1.9753 - val_accuracy: 0.7835\n",
      "Epoch 64/100\n",
      " - 4s - loss: 0.1113 - accuracy: 0.9718 - val_loss: 1.9618 - val_accuracy: 0.7880\n",
      "Epoch 65/100\n",
      " - 4s - loss: 0.1103 - accuracy: 0.9716 - val_loss: 2.0101 - val_accuracy: 0.7861\n",
      "Epoch 66/100\n",
      " - 4s - loss: 0.1062 - accuracy: 0.9730 - val_loss: 2.0465 - val_accuracy: 0.7835\n",
      "Epoch 67/100\n",
      " - 4s - loss: 0.1171 - accuracy: 0.9691 - val_loss: 2.0436 - val_accuracy: 0.7844\n",
      "Epoch 68/100\n",
      " - 4s - loss: 0.1212 - accuracy: 0.9666 - val_loss: 2.0621 - val_accuracy: 0.7824\n",
      "Epoch 69/100\n",
      " - 4s - loss: 0.1048 - accuracy: 0.9731 - val_loss: 2.0944 - val_accuracy: 0.7852\n",
      "Epoch 70/100\n",
      " - 4s - loss: 0.1047 - accuracy: 0.9732 - val_loss: 2.0949 - val_accuracy: 0.7857\n",
      "Epoch 71/100\n",
      " - 4s - loss: 0.0993 - accuracy: 0.9750 - val_loss: 2.1311 - val_accuracy: 0.7853\n",
      "Epoch 72/100\n",
      " - 4s - loss: 0.0999 - accuracy: 0.9751 - val_loss: 2.1502 - val_accuracy: 0.7869\n",
      "Epoch 73/100\n",
      " - 4s - loss: 0.1081 - accuracy: 0.9709 - val_loss: 2.1707 - val_accuracy: 0.7840\n",
      "Epoch 74/100\n",
      " - 4s - loss: 0.0976 - accuracy: 0.9758 - val_loss: 2.2396 - val_accuracy: 0.7837\n",
      "Epoch 75/100\n",
      " - 4s - loss: 0.0866 - accuracy: 0.9800 - val_loss: 2.2185 - val_accuracy: 0.7864\n",
      "Epoch 76/100\n",
      " - 4s - loss: 0.0950 - accuracy: 0.9761 - val_loss: 2.2382 - val_accuracy: 0.7849\n",
      "Epoch 77/100\n",
      " - 4s - loss: 0.0833 - accuracy: 0.9815 - val_loss: 2.2315 - val_accuracy: 0.7843\n",
      "Epoch 78/100\n",
      " - 4s - loss: 0.0909 - accuracy: 0.9777 - val_loss: 2.2871 - val_accuracy: 0.7848\n",
      "Epoch 79/100\n",
      " - 4s - loss: 0.0856 - accuracy: 0.9797 - val_loss: 2.3212 - val_accuracy: 0.7828\n",
      "Epoch 80/100\n",
      " - 4s - loss: 0.1006 - accuracy: 0.9734 - val_loss: 2.3081 - val_accuracy: 0.7850\n",
      "Epoch 81/100\n",
      " - 4s - loss: 0.0854 - accuracy: 0.9799 - val_loss: 2.3005 - val_accuracy: 0.7871\n",
      "Epoch 82/100\n",
      " - 4s - loss: 0.0795 - accuracy: 0.9821 - val_loss: 2.3329 - val_accuracy: 0.7839\n",
      "Epoch 83/100\n",
      " - 4s - loss: 0.0767 - accuracy: 0.9831 - val_loss: 2.3834 - val_accuracy: 0.7854\n",
      "Epoch 84/100\n",
      " - 4s - loss: 0.0789 - accuracy: 0.9823 - val_loss: 2.3834 - val_accuracy: 0.7828\n",
      "Epoch 85/100\n",
      " - 4s - loss: 0.0729 - accuracy: 0.9852 - val_loss: 2.3868 - val_accuracy: 0.7875\n",
      "Epoch 86/100\n",
      " - 4s - loss: 0.0710 - accuracy: 0.9853 - val_loss: 2.3964 - val_accuracy: 0.7853\n",
      "Epoch 87/100\n",
      " - 4s - loss: 0.0711 - accuracy: 0.9859 - val_loss: 2.4145 - val_accuracy: 0.7843\n",
      "Epoch 88/100\n",
      " - 4s - loss: 0.0681 - accuracy: 0.9866 - val_loss: 2.4420 - val_accuracy: 0.7854\n",
      "Epoch 89/100\n",
      " - 4s - loss: 0.0712 - accuracy: 0.9852 - val_loss: 2.4702 - val_accuracy: 0.7846\n",
      "Epoch 90/100\n",
      " - 4s - loss: 0.0690 - accuracy: 0.9862 - val_loss: 2.4747 - val_accuracy: 0.7838\n",
      "Epoch 91/100\n",
      " - 4s - loss: 0.0668 - accuracy: 0.9870 - val_loss: 2.4888 - val_accuracy: 0.7844\n",
      "Epoch 92/100\n",
      " - 4s - loss: 0.0671 - accuracy: 0.9871 - val_loss: 2.5174 - val_accuracy: 0.7844\n",
      "Epoch 93/100\n",
      " - 4s - loss: 0.0700 - accuracy: 0.9852 - val_loss: 2.5252 - val_accuracy: 0.7843\n",
      "Epoch 94/100\n",
      " - 4s - loss: 0.0679 - accuracy: 0.9864 - val_loss: 2.5616 - val_accuracy: 0.7838\n",
      "Epoch 95/100\n",
      " - 4s - loss: 0.0735 - accuracy: 0.9837 - val_loss: 2.6152 - val_accuracy: 0.7810\n",
      "Epoch 96/100\n",
      " - 4s - loss: 0.0675 - accuracy: 0.9865 - val_loss: 2.5774 - val_accuracy: 0.7850\n",
      "Epoch 97/100\n",
      " - 4s - loss: 0.0706 - accuracy: 0.9850 - val_loss: 2.5740 - val_accuracy: 0.7860\n",
      "Epoch 98/100\n",
      " - 4s - loss: 0.0627 - accuracy: 0.9883 - val_loss: 2.5848 - val_accuracy: 0.7836\n",
      "Epoch 99/100\n",
      " - 4s - loss: 0.0594 - accuracy: 0.9896 - val_loss: 2.6073 - val_accuracy: 0.7867\n",
      "Epoch 100/100\n",
      " - 4s - loss: 0.0542 - accuracy: 0.9916 - val_loss: 2.6339 - val_accuracy: 0.7831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc673014da0>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.05726525291756939\n",
    "hidden_nodes = 256\n",
    "output_nodes = 10\n",
    "Lambda = 8.231254283285364e-05\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_nodes, input_shape=(1024,), activation='relu'))\n",
    "model.add(Dense(hidden_nodes, activation='relu'))\n",
    "model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "\n",
    "sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_split = 0.20, epochs=100, shuffle = True, batch_size=1000, verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "oL_9TaRWKCtA",
    "outputId": "995df895-4af6-49a8-b512-3429aa7b3dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 330,762\n",
      "Trainable params: 330,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Z5IOtbqWKCtC",
    "outputId": "fa39ecc1-e159-47b8-b1ab-ed432aed49b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 46us/step\n",
      "Test accuracy:  0.8573333621025085\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "k-1qchK-KCtD",
    "outputId": "333bea62-ca3b-47d2-c546-e85bf97b1420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 38us/step\n",
      "Accuracy: 0.8573333621025085\n",
      "Recall_score: 0.857126883928298\n",
      "Precision_score: 0.8588120391216251\n",
      "F-score: 0.857399888585852\n",
      "18000/18000 [==============================] - 1s 39us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1611,   15,   20,   23,   15,    6,   26,   17,   41,   40],\n",
       "       [  25, 1540,   44,   42,   31,   11,   19,   59,   40,   17],\n",
       "       [  17,    9, 1603,   44,   14,    8,    6,   36,   41,   25],\n",
       "       [  15,   18,   50, 1417,    4,   83,   25,   30,   54,   23],\n",
       "       [  16,   45,   21,   27, 1563,   16,   36,   17,   38,   33],\n",
       "       [  16,    8,   17,   87,    8, 1467,   71,   11,   65,   18],\n",
       "       [  33,   15,   12,   21,   17,   47, 1556,   15,  104,   12],\n",
       "       [  12,   30,   46,   26,    6,   13,   13, 1632,    9,   21],\n",
       "       [  30,   24,   29,   42,    5,   21,   59,   10, 1555,   37],\n",
       "       [  59,   18,   36,   44,   17,   41,   13,   27,   61, 1488]])"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_cls = model.predict_classes(X_test, batch_size=200, verbose=0)\n",
    "y_labels = np.argmax(y_test, axis=1)\n",
    "print('Accuracy: '+ str(model.evaluate(X_test,y_test)[1]))\n",
    "print('Recall_score: ' + str(recall_score(y_labels,Y_pred_cls, average='macro')))\n",
    "print('Precision_score: ' + str(precision_score(y_labels, Y_pred_cls, average='macro')))\n",
    "print('F-score: ' + str(f1_score(y_labels,Y_pred_cls, average='macro')))\n",
    "Score('NNDA', X_test,y_test, y_labels, Y_pred_cls)\n",
    "confusion_matrix(y_labels, Y_pred_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-5cHyZCunGi"
   },
   "source": [
    "#### Task: Implementing batch normalization for training the neural network with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xu1bPCYCKCtF"
   },
   "outputs": [],
   "source": [
    "def train_and_test_loop_ht(iterations, lr, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,), kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(output_nodes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = lr)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=iterations, batch_size=1000, verbose= 0)\n",
    "    score = model.evaluate(X_train, y_train, verbose=0)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78sd4c2cKCtG"
   },
   "outputs": [],
   "source": [
    "# for k in range(1,11):\n",
    "#     lr = math.pow(10, np.random.uniform(-4.0, -1.0))\n",
    "#     best_acc = train_and_test_loop_ht(100, lr, False)\n",
    "#     print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}\\n\".format(k, 10, best_acc, lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Batch Normalization & Adam optimizer applied \n",
    "* Multiple rounds of hyperparameter tuning completed\n",
    "* After completing above steps below learning rate was finalized for fourth Neural Network with batch normalization & data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "inblMl1QKCtI",
    "outputId": "1ce89cf0-c8d1-4883-b408-a86cc8be770a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100800 samples, validate on 25200 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.9588 - accuracy: 0.3544 - val_loss: 1.6636 - val_accuracy: 0.4906\n",
      "Epoch 2/100\n",
      " - 5s - loss: 1.3640 - accuracy: 0.6252 - val_loss: 1.2240 - val_accuracy: 0.6121\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.1089 - accuracy: 0.7065 - val_loss: 1.0590 - val_accuracy: 0.6617\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.9610 - accuracy: 0.7452 - val_loss: 0.9820 - val_accuracy: 0.6838\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.8551 - accuracy: 0.7707 - val_loss: 0.9299 - val_accuracy: 0.7061\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.7718 - accuracy: 0.7915 - val_loss: 0.8945 - val_accuracy: 0.7202\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.7061 - accuracy: 0.8075 - val_loss: 0.8760 - val_accuracy: 0.7277\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.6516 - accuracy: 0.8223 - val_loss: 0.8447 - val_accuracy: 0.7408\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.6068 - accuracy: 0.8341 - val_loss: 0.8428 - val_accuracy: 0.7459\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.5692 - accuracy: 0.8439 - val_loss: 0.8307 - val_accuracy: 0.7522\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.5357 - accuracy: 0.8524 - val_loss: 0.8180 - val_accuracy: 0.7585\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.5075 - accuracy: 0.8591 - val_loss: 0.8165 - val_accuracy: 0.7603\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.4825 - accuracy: 0.8664 - val_loss: 0.8106 - val_accuracy: 0.7631\n",
      "Epoch 14/100\n",
      " - 5s - loss: 0.4604 - accuracy: 0.8726 - val_loss: 0.8117 - val_accuracy: 0.7659\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.4400 - accuracy: 0.8773 - val_loss: 0.8087 - val_accuracy: 0.7683\n",
      "Epoch 16/100\n",
      " - 5s - loss: 0.4212 - accuracy: 0.8826 - val_loss: 0.8229 - val_accuracy: 0.7704\n",
      "Epoch 17/100\n",
      " - 5s - loss: 0.4034 - accuracy: 0.8876 - val_loss: 0.8215 - val_accuracy: 0.7713\n",
      "Epoch 18/100\n",
      " - 5s - loss: 0.3877 - accuracy: 0.8921 - val_loss: 0.8259 - val_accuracy: 0.7706\n",
      "Epoch 19/100\n",
      " - 5s - loss: 0.3730 - accuracy: 0.8968 - val_loss: 0.8382 - val_accuracy: 0.7698\n",
      "Epoch 20/100\n",
      " - 5s - loss: 0.3587 - accuracy: 0.9012 - val_loss: 0.8413 - val_accuracy: 0.7712\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.3475 - accuracy: 0.9031 - val_loss: 0.8401 - val_accuracy: 0.7748\n",
      "Epoch 22/100\n",
      " - 5s - loss: 0.3353 - accuracy: 0.9077 - val_loss: 0.8488 - val_accuracy: 0.7750\n",
      "Epoch 23/100\n",
      " - 5s - loss: 0.3211 - accuracy: 0.9123 - val_loss: 0.8637 - val_accuracy: 0.7744\n",
      "Epoch 24/100\n",
      " - 5s - loss: 0.3118 - accuracy: 0.9150 - val_loss: 0.8721 - val_accuracy: 0.7732\n",
      "Epoch 25/100\n",
      " - 5s - loss: 0.3004 - accuracy: 0.9169 - val_loss: 0.8820 - val_accuracy: 0.7749\n",
      "Epoch 26/100\n",
      " - 5s - loss: 0.2911 - accuracy: 0.9209 - val_loss: 0.8905 - val_accuracy: 0.7725\n",
      "Epoch 27/100\n",
      " - 5s - loss: 0.2817 - accuracy: 0.9230 - val_loss: 0.8956 - val_accuracy: 0.7725\n",
      "Epoch 28/100\n",
      " - 5s - loss: 0.2736 - accuracy: 0.9253 - val_loss: 0.9061 - val_accuracy: 0.7750\n",
      "Epoch 29/100\n",
      " - 5s - loss: 0.2634 - accuracy: 0.9285 - val_loss: 0.9060 - val_accuracy: 0.7770\n",
      "Epoch 30/100\n",
      " - 5s - loss: 0.2548 - accuracy: 0.9307 - val_loss: 0.9273 - val_accuracy: 0.7739\n",
      "Epoch 31/100\n",
      " - 5s - loss: 0.2471 - accuracy: 0.9332 - val_loss: 0.9570 - val_accuracy: 0.7745\n",
      "Epoch 32/100\n",
      " - 5s - loss: 0.2418 - accuracy: 0.9351 - val_loss: 0.9695 - val_accuracy: 0.7724\n",
      "Epoch 33/100\n",
      " - 5s - loss: 0.2323 - accuracy: 0.9389 - val_loss: 0.9835 - val_accuracy: 0.7706\n",
      "Epoch 34/100\n",
      " - 5s - loss: 0.2267 - accuracy: 0.9388 - val_loss: 0.9782 - val_accuracy: 0.7746\n",
      "Epoch 35/100\n",
      " - 5s - loss: 0.2196 - accuracy: 0.9423 - val_loss: 0.9835 - val_accuracy: 0.7765\n",
      "Epoch 36/100\n",
      " - 5s - loss: 0.2118 - accuracy: 0.9443 - val_loss: 1.0106 - val_accuracy: 0.7739\n",
      "Epoch 37/100\n",
      " - 5s - loss: 0.2070 - accuracy: 0.9458 - val_loss: 1.0123 - val_accuracy: 0.7779\n",
      "Epoch 38/100\n",
      " - 5s - loss: 0.2007 - accuracy: 0.9470 - val_loss: 1.0406 - val_accuracy: 0.7724\n",
      "Epoch 39/100\n",
      " - 5s - loss: 0.1939 - accuracy: 0.9491 - val_loss: 1.0383 - val_accuracy: 0.7750\n",
      "Epoch 40/100\n",
      " - 5s - loss: 0.1897 - accuracy: 0.9503 - val_loss: 1.0532 - val_accuracy: 0.7754\n",
      "Epoch 41/100\n",
      " - 5s - loss: 0.1842 - accuracy: 0.9524 - val_loss: 1.0696 - val_accuracy: 0.7729\n",
      "Epoch 42/100\n",
      " - 5s - loss: 0.1803 - accuracy: 0.9530 - val_loss: 1.0903 - val_accuracy: 0.7720\n",
      "Epoch 43/100\n",
      " - 5s - loss: 0.1748 - accuracy: 0.9548 - val_loss: 1.1057 - val_accuracy: 0.7700\n",
      "Epoch 44/100\n",
      " - 5s - loss: 0.1719 - accuracy: 0.9551 - val_loss: 1.1273 - val_accuracy: 0.7708\n",
      "Epoch 45/100\n",
      " - 5s - loss: 0.1648 - accuracy: 0.9571 - val_loss: 1.1370 - val_accuracy: 0.7707\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.1601 - accuracy: 0.9587 - val_loss: 1.1467 - val_accuracy: 0.7718\n",
      "Epoch 47/100\n",
      " - 5s - loss: 0.1554 - accuracy: 0.9600 - val_loss: 1.1870 - val_accuracy: 0.7673\n",
      "Epoch 48/100\n",
      " - 5s - loss: 0.1512 - accuracy: 0.9617 - val_loss: 1.1666 - val_accuracy: 0.7735\n",
      "Epoch 49/100\n",
      " - 5s - loss: 0.1474 - accuracy: 0.9631 - val_loss: 1.2138 - val_accuracy: 0.7669\n",
      "Epoch 50/100\n",
      " - 6s - loss: 0.1437 - accuracy: 0.9637 - val_loss: 1.2068 - val_accuracy: 0.7702\n",
      "Epoch 51/100\n",
      " - 7s - loss: 0.1389 - accuracy: 0.9654 - val_loss: 1.2112 - val_accuracy: 0.7724\n",
      "Epoch 52/100\n",
      " - 5s - loss: 0.1376 - accuracy: 0.9648 - val_loss: 1.2375 - val_accuracy: 0.7698\n",
      "Epoch 53/100\n",
      " - 5s - loss: 0.1338 - accuracy: 0.9662 - val_loss: 1.2571 - val_accuracy: 0.7708\n",
      "Epoch 54/100\n",
      " - 5s - loss: 0.1298 - accuracy: 0.9670 - val_loss: 1.2675 - val_accuracy: 0.7685\n",
      "Epoch 55/100\n",
      " - 5s - loss: 0.1289 - accuracy: 0.9675 - val_loss: 1.2934 - val_accuracy: 0.7692\n",
      "Epoch 56/100\n",
      " - 5s - loss: 0.1251 - accuracy: 0.9679 - val_loss: 1.3225 - val_accuracy: 0.7667\n",
      "Epoch 57/100\n",
      " - 5s - loss: 0.1195 - accuracy: 0.9702 - val_loss: 1.3151 - val_accuracy: 0.7673\n",
      "Epoch 58/100\n",
      " - 5s - loss: 0.1170 - accuracy: 0.9708 - val_loss: 1.3778 - val_accuracy: 0.7647\n",
      "Epoch 59/100\n",
      " - 5s - loss: 0.1152 - accuracy: 0.9713 - val_loss: 1.4009 - val_accuracy: 0.7627\n",
      "Epoch 60/100\n",
      " - 5s - loss: 0.1136 - accuracy: 0.9714 - val_loss: 1.3911 - val_accuracy: 0.7649\n",
      "Epoch 61/100\n",
      " - 5s - loss: 0.1095 - accuracy: 0.9723 - val_loss: 1.3785 - val_accuracy: 0.7652\n",
      "Epoch 62/100\n",
      " - 5s - loss: 0.1071 - accuracy: 0.9733 - val_loss: 1.4423 - val_accuracy: 0.7638\n",
      "Epoch 63/100\n",
      " - 5s - loss: 0.1068 - accuracy: 0.9728 - val_loss: 1.4233 - val_accuracy: 0.7677\n",
      "Epoch 64/100\n",
      " - 5s - loss: 0.1008 - accuracy: 0.9756 - val_loss: 1.4187 - val_accuracy: 0.7668\n",
      "Epoch 65/100\n",
      " - 5s - loss: 0.0982 - accuracy: 0.9759 - val_loss: 1.4249 - val_accuracy: 0.7683\n",
      "Epoch 66/100\n",
      " - 5s - loss: 0.0957 - accuracy: 0.9767 - val_loss: 1.5011 - val_accuracy: 0.7621\n",
      "Epoch 67/100\n",
      " - 5s - loss: 0.0960 - accuracy: 0.9762 - val_loss: 1.5078 - val_accuracy: 0.7635\n",
      "Epoch 68/100\n",
      " - 5s - loss: 0.0924 - accuracy: 0.9776 - val_loss: 1.4874 - val_accuracy: 0.7672\n",
      "Epoch 69/100\n",
      " - 5s - loss: 0.0912 - accuracy: 0.9779 - val_loss: 1.5617 - val_accuracy: 0.7627\n",
      "Epoch 70/100\n",
      " - 5s - loss: 0.0896 - accuracy: 0.9779 - val_loss: 1.5301 - val_accuracy: 0.7678\n",
      "Epoch 71/100\n",
      " - 5s - loss: 0.0865 - accuracy: 0.9791 - val_loss: 1.5505 - val_accuracy: 0.7654\n",
      "Epoch 72/100\n",
      " - 5s - loss: 0.0879 - accuracy: 0.9779 - val_loss: 1.5553 - val_accuracy: 0.7678\n",
      "Epoch 73/100\n",
      " - 5s - loss: 0.0843 - accuracy: 0.9789 - val_loss: 1.6051 - val_accuracy: 0.7644\n",
      "Epoch 74/100\n",
      " - 5s - loss: 0.0821 - accuracy: 0.9802 - val_loss: 1.5995 - val_accuracy: 0.7663\n",
      "Epoch 75/100\n",
      " - 5s - loss: 0.0797 - accuracy: 0.9809 - val_loss: 1.5888 - val_accuracy: 0.7685\n",
      "Epoch 76/100\n",
      " - 5s - loss: 0.0788 - accuracy: 0.9808 - val_loss: 1.6823 - val_accuracy: 0.7618\n",
      "Epoch 77/100\n",
      " - 5s - loss: 0.0753 - accuracy: 0.9825 - val_loss: 1.6614 - val_accuracy: 0.7637\n",
      "Epoch 78/100\n",
      " - 5s - loss: 0.0757 - accuracy: 0.9819 - val_loss: 1.7075 - val_accuracy: 0.7623\n",
      "Epoch 79/100\n",
      " - 5s - loss: 0.0744 - accuracy: 0.9819 - val_loss: 1.7053 - val_accuracy: 0.7620\n",
      "Epoch 80/100\n",
      " - 5s - loss: 0.0726 - accuracy: 0.9825 - val_loss: 1.7126 - val_accuracy: 0.7631\n",
      "Epoch 81/100\n",
      " - 5s - loss: 0.0693 - accuracy: 0.9835 - val_loss: 1.7401 - val_accuracy: 0.7651\n",
      "Epoch 82/100\n",
      " - 5s - loss: 0.0690 - accuracy: 0.9831 - val_loss: 1.7416 - val_accuracy: 0.7654\n",
      "Epoch 83/100\n",
      " - 5s - loss: 0.0683 - accuracy: 0.9833 - val_loss: 1.7659 - val_accuracy: 0.7633\n",
      "Epoch 84/100\n",
      " - 5s - loss: 0.0701 - accuracy: 0.9825 - val_loss: 1.7799 - val_accuracy: 0.7656\n",
      "Epoch 85/100\n",
      " - 5s - loss: 0.0663 - accuracy: 0.9838 - val_loss: 1.7757 - val_accuracy: 0.7642\n",
      "Epoch 86/100\n",
      " - 5s - loss: 0.0630 - accuracy: 0.9849 - val_loss: 1.8135 - val_accuracy: 0.7634\n",
      "Epoch 87/100\n",
      " - 5s - loss: 0.0644 - accuracy: 0.9844 - val_loss: 1.8662 - val_accuracy: 0.7611\n",
      "Epoch 88/100\n",
      " - 5s - loss: 0.0635 - accuracy: 0.9842 - val_loss: 1.8428 - val_accuracy: 0.7612\n",
      "Epoch 89/100\n",
      " - 5s - loss: 0.0630 - accuracy: 0.9845 - val_loss: 1.8672 - val_accuracy: 0.7622\n",
      "Epoch 90/100\n",
      " - 5s - loss: 0.0580 - accuracy: 0.9866 - val_loss: 1.8948 - val_accuracy: 0.7621\n",
      "Epoch 91/100\n",
      " - 5s - loss: 0.0597 - accuracy: 0.9854 - val_loss: 1.9005 - val_accuracy: 0.7609\n",
      "Epoch 92/100\n",
      " - 5s - loss: 0.0579 - accuracy: 0.9858 - val_loss: 1.9076 - val_accuracy: 0.7628\n",
      "Epoch 93/100\n",
      " - 5s - loss: 0.0592 - accuracy: 0.9852 - val_loss: 1.8835 - val_accuracy: 0.7635\n",
      "Epoch 94/100\n",
      " - 5s - loss: 0.0568 - accuracy: 0.9861 - val_loss: 1.9182 - val_accuracy: 0.7658\n",
      "Epoch 95/100\n",
      " - 5s - loss: 0.0551 - accuracy: 0.9869 - val_loss: 1.9422 - val_accuracy: 0.7626\n",
      "Epoch 96/100\n",
      " - 5s - loss: 0.0552 - accuracy: 0.9865 - val_loss: 1.9457 - val_accuracy: 0.7634\n",
      "Epoch 97/100\n",
      " - 5s - loss: 0.0583 - accuracy: 0.9848 - val_loss: 1.9626 - val_accuracy: 0.7647\n",
      "Epoch 98/100\n",
      " - 5s - loss: 0.0520 - accuracy: 0.9874 - val_loss: 1.9747 - val_accuracy: 0.7635\n",
      "Epoch 99/100\n",
      " - 5s - loss: 0.0521 - accuracy: 0.9877 - val_loss: 2.0110 - val_accuracy: 0.7645\n",
      "Epoch 100/100\n",
      " - 5s - loss: 0.0523 - accuracy: 0.9874 - val_loss: 2.0064 - val_accuracy: 0.7642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc672eb7f28>"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.0001171682966818011\n",
    "hidden_nodes = 256\n",
    "output_nodes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_nodes, input_shape=(1024,), kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(hidden_nodes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_nodes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr = learning_rate)\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_split = 0.20, epochs=100, shuffle = True, batch_size=1000, verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "_ym2FDEkKCtK",
    "outputId": "1d9af222-8c2e-4931-befb-66909a4f4a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 332,810\n",
      "Trainable params: 331,786\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "WV1TrMvLKCtM",
    "outputId": "364d0bb6-93c0-40cc-c271-3c603e0bd194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 53us/step\n",
      "Test accuracy:  0.8172777891159058\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "UAe-OHtdKCtN",
    "outputId": "061e312c-2c36-4e6c-f07b-6a05c1b71905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 53us/step\n",
      "Accuracy: 0.8172777891159058\n",
      "Recall_score: 0.8175374298264956\n",
      "Precision_score: 0.8329700016140714\n",
      "F-score: 0.8196344612152201\n",
      "18000/18000 [==============================] - 1s 51us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1556,   24,    7,   38,   15,    7,    7,   10,   12,  138],\n",
       "       [  29, 1515,   15,   73,   35,   16,   10,   44,   12,   79],\n",
       "       [  28,   21, 1482,   76,   19,   11,    1,   38,   23,  104],\n",
       "       [  15,   14,   16, 1464,   11,   77,   11,   21,   18,   72],\n",
       "       [  19,   56,   23,   50, 1494,   23,   17,   11,   13,  106],\n",
       "       [  13,   12,    5,  156,    8, 1428,   21,   12,   21,   92],\n",
       "       [  61,   19,   12,   57,   23,  120, 1363,   18,   79,   80],\n",
       "       [  31,   60,   46,   73,    9,   11,    4, 1498,   12,   64],\n",
       "       [  41,   30,   13,  149,   11,   52,   29,    4, 1292,  191],\n",
       "       [  28,   16,   12,   48,   14,   30,    9,   16,   12, 1619]])"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_cls = model.predict_classes(X_test, batch_size=200, verbose=0)\n",
    "y_labels = np.argmax(y_test, axis=1)\n",
    "print('Accuracy: '+ str(model.evaluate(X_test,y_test)[1]))\n",
    "print('Recall_score: ' + str(recall_score(y_labels,Y_pred_cls, average='macro')))\n",
    "print('Precision_score: ' + str(precision_score(y_labels, Y_pred_cls, average='macro')))\n",
    "print('F-score: ' + str(f1_score(y_labels,Y_pred_cls, average='macro')))\n",
    "Score('NNBNDA', X_test,y_test, y_labels, Y_pred_cls)\n",
    "confusion_matrix(y_labels, Y_pred_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYpCcz1sunGs"
   },
   "source": [
    "#### Task: Print the classification accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "Tt9WEk1hunGt",
    "outputId": "64b38e9a-0a40-44fd-fb9d-7b0d57c82272"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "      <th>NNBN</th>\n",
       "      <th>NNDA</th>\n",
       "      <th>NNBNDA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.8357222080230713</td>\n",
       "      <td>0.8146666884422302</td>\n",
       "      <td>0.8573333621025085</td>\n",
       "      <td>0.8172777891159058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.8379401971779197</td>\n",
       "      <td>0.8220514983678102</td>\n",
       "      <td>0.8588120391216251</td>\n",
       "      <td>0.8329700016140714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.8355198542572433</td>\n",
       "      <td>0.8146233095623353</td>\n",
       "      <td>0.857126883928298</td>\n",
       "      <td>0.8175374298264956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.8358035411444584</td>\n",
       "      <td>0.815625369039197</td>\n",
       "      <td>0.857399888585852</td>\n",
       "      <td>0.8196344612152201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NN  ...              NNBNDA\n",
       "Metrics                        ...                    \n",
       "Accuracy   0.8357222080230713  ...  0.8172777891159058\n",
       "Precision  0.8379401971779197  ...  0.8329700016140714\n",
       "Recall     0.8355198542572433  ...  0.8175374298264956\n",
       "F1 Score   0.8358035411444584  ...  0.8196344612152201\n",
       "\n",
       "[4 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Accuracy_Score.set_index('Metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "Four models were created\n",
    "* Neural Network (NN)\n",
    "* Neural Network with Batch Normalization (NNBN)\n",
    "* Neural Network with Data Augmentation (NNDA)\n",
    "* Neural Network with Batch Normalization & Data Augmentation (NNBNDA)\n",
    "* Out of the four models neural network with data augmentation appears to be performing better with 85.7% accuracy on test data\n",
    "* Model is still overfit and further exploration can lead to better performance"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_Neural_Networks_Sanju_Mathew.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
